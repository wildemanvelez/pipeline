{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "\n",
    "# The following code is used for hiding the warnings and make this notebook clearer.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data', names=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "names= ['buying',\n",
    "        'maint',\n",
    "'doors',\n",
    "'persons',\n",
    "'lug_boot',\n",
    "'safety ',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>vhigh</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vhigh</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vhigh</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vhigh</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vhigh</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      buying maint doors persons lug_boot safety \n",
       "vhigh  vhigh     2     2   small      low   unacc\n",
       "vhigh  vhigh     2     2   small      med   unacc\n",
       "vhigh  vhigh     2     2   small     high   unacc\n",
       "vhigh  vhigh     2     2     med      low   unacc\n",
       "vhigh  vhigh     2     2     med      med   unacc"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer,LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nor_x = LabelEncoder\n",
    "nor_y = LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.get_dummies(x)\n",
    "y = pd.get_dummies(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>good</th>\n",
       "      <th>unacc</th>\n",
       "      <th>vgood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"30\" valign=\"top\">vhigh</th>\n",
       "      <th>vhigh</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vhigh</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vhigh</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vhigh</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vhigh</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vhigh</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vhigh</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vhigh</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vhigh</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vhigh</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vhigh</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vhigh</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vhigh</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vhigh</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vhigh</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vhigh</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vhigh</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vhigh</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vhigh</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vhigh</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vhigh</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vhigh</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vhigh</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vhigh</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vhigh</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vhigh</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vhigh</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vhigh</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vhigh</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vhigh</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"30\" valign=\"top\">low</th>\n",
       "      <th>low</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1728 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             acc  good  unacc  vgood\n",
       "vhigh vhigh    0     0      1      0\n",
       "      vhigh    0     0      1      0\n",
       "      vhigh    0     0      1      0\n",
       "      vhigh    0     0      1      0\n",
       "      vhigh    0     0      1      0\n",
       "      vhigh    0     0      1      0\n",
       "      vhigh    0     0      1      0\n",
       "      vhigh    0     0      1      0\n",
       "      vhigh    0     0      1      0\n",
       "      vhigh    0     0      1      0\n",
       "      vhigh    0     0      1      0\n",
       "      vhigh    0     0      1      0\n",
       "      vhigh    0     0      1      0\n",
       "      vhigh    0     0      1      0\n",
       "      vhigh    0     0      1      0\n",
       "      vhigh    0     0      1      0\n",
       "      vhigh    0     0      1      0\n",
       "      vhigh    0     0      1      0\n",
       "      vhigh    0     0      1      0\n",
       "      vhigh    0     0      1      0\n",
       "      vhigh    0     0      1      0\n",
       "      vhigh    0     0      1      0\n",
       "      vhigh    0     0      1      0\n",
       "      vhigh    0     0      1      0\n",
       "      vhigh    0     0      1      0\n",
       "      vhigh    0     0      1      0\n",
       "      vhigh    0     0      1      0\n",
       "      vhigh    0     0      1      0\n",
       "      vhigh    0     0      1      0\n",
       "      vhigh    0     0      1      0\n",
       "...          ...   ...    ...    ...\n",
       "low   low      0     0      1      0\n",
       "      low      0     1      0      0\n",
       "      low      0     0      0      1\n",
       "      low      0     0      1      0\n",
       "      low      0     0      1      0\n",
       "      low      0     0      1      0\n",
       "      low      0     0      1      0\n",
       "      low      0     0      1      0\n",
       "      low      0     0      1      0\n",
       "      low      0     0      1      0\n",
       "      low      0     0      1      0\n",
       "      low      0     0      1      0\n",
       "      low      0     0      1      0\n",
       "      low      1     0      0      0\n",
       "      low      0     1      0      0\n",
       "      low      0     0      1      0\n",
       "      low      0     1      0      0\n",
       "      low      0     0      0      1\n",
       "      low      0     0      1      0\n",
       "      low      0     1      0      0\n",
       "      low      0     0      0      1\n",
       "      low      0     0      1      0\n",
       "      low      1     0      0      0\n",
       "      low      0     1      0      0\n",
       "      low      0     0      1      0\n",
       "      low      0     1      0      0\n",
       "      low      0     0      0      1\n",
       "      low      0     0      1      0\n",
       "      low      0     1      0      0\n",
       "      low      0     0      0      1\n",
       "\n",
       "[1728 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tanh(x):\n",
    "    return (1.0 - numpy.exp(-2*x))/(1.0 + numpy.exp(-2*x))\n",
    "\n",
    "def tanh_derivative(x):\n",
    "    return (1 + tanh(x))*(1 - tanh(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    #########\n",
    "    # parameters\n",
    "    # ----------\n",
    "    # self:      the class object itself\n",
    "    # net_arch:  consists of a list of integers, indicating\n",
    "    #            the number of neurons in each layer, i.e. the network architecture\n",
    "    #########\n",
    "    def __init__(self, net_arch):\n",
    "        numpy.random.seed(0)\n",
    "        \n",
    "        # Initialized the weights, making sure we also \n",
    "        # initialize the weights for the biases that we will add later\n",
    "        self.activity = tanh\n",
    "        self.activity_derivative = tanh_derivative\n",
    "        self.layers = len(net_arch)\n",
    "        self.steps_per_epoch = 1\n",
    "        self.arch = net_arch\n",
    "        self.weights = []\n",
    "\n",
    "        # Random initialization with range of weight values (-1,1)\n",
    "        for layer in range(self.layers - 1):\n",
    "            w = 2*numpy.random.rand(net_arch[layer] + 1, net_arch[layer+1]) - 1\n",
    "            self.weights.append(w)\n",
    "    \n",
    "    def _forward_prop(self, x):\n",
    "        y = x\n",
    "\n",
    "        for i in range(len(self.weights)-1):\n",
    "            activation = numpy.dot(y[i], self.weights[i])\n",
    "            activity = self.activity(activation)\n",
    "\n",
    "            # add the bias for the next layer\n",
    "            activity = numpy.concatenate((numpy.ones(1), numpy.array(activity)))\n",
    "            y.append(activity)\n",
    "\n",
    "        # last layer\n",
    "        activation = numpy.dot(y[-1], self.weights[-1])\n",
    "        activity = self.activity(activation)\n",
    "        y.append(activity)\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    def _back_prop(self, y, target, learning_rate):\n",
    "        error = target - y[-1]\n",
    "        delta_vec = [error * self.activity_derivative(y[-1])]\n",
    "\n",
    "        # we need to begin from the back, from the next to last layer\n",
    "        for i in range(self.layers-2, 0, -1):\n",
    "            error = delta_vec[-1].dot(self.weights[i][1:].T)\n",
    "            error = error*self.activity_derivative(y[i][1:])\n",
    "            delta_vec.append(error)\n",
    "\n",
    "        # Now we need to set the values from back to front\n",
    "        delta_vec.reverse()\n",
    "        \n",
    "        # Finally, we adjust the weights, using the backpropagation rules\n",
    "        for i in range(len(self.weights)):\n",
    "            layer = y[i].reshape(1, self.arch[i]+1)\n",
    "            delta = delta_vec[i].reshape(1, self.arch[i+1])\n",
    "            self.weights[i] += learning_rate*layer.T.dot(delta)\n",
    "    \n",
    "    #########\n",
    "    # parameters\n",
    "    # ----------\n",
    "    # self:    the class object itself\n",
    "    # data:    the set of all possible pairs of booleans True or False indicated by the integers 1 or 0\n",
    "    # labels:  the result of the logical operation 'xor' on each of those input pairs\n",
    "    #########\n",
    "    def fit(self, data, labels, learning_rate=0.1, epochs=100):\n",
    "        \n",
    "        # Add bias units to the input layer - \n",
    "        # add a \"1\" to the input data (the always-on bias neuron)\n",
    "        ones = numpy.ones((1, data.shape[0]))\n",
    "        Z = numpy.concatenate((ones.T, data), axis=1)\n",
    "        \n",
    "        for k in range(epochs):\n",
    "            if (k+1) % 10000 == 0:\n",
    "                print('epochs: {}'.format(k+1))\n",
    "        \n",
    "            sample = numpy.random.randint(X.shape[0])\n",
    "\n",
    "            # We will now go ahead and set up our feed-forward propagation:\n",
    "            x = [Z[sample]]\n",
    "            y = self._forward_prop(x)\n",
    "\n",
    "            # Now we do our back-propagation of the error to adjust the weights:\n",
    "            target = labels[sample]\n",
    "            self._back_prop(y, target, learning_rate)\n",
    "    \n",
    "    #########\n",
    "    # the predict function is used to check the prediction result of\n",
    "    # this neural network.\n",
    "    # \n",
    "    # parameters\n",
    "    # ----------\n",
    "    # self:   the class object itself\n",
    "    # x:      single input data\n",
    "    #########\n",
    "    def predict_single_data(self, x):\n",
    "        val = numpy.concatenate((numpy.ones(1).T, numpy.array(x)))\n",
    "        for i in range(0, len(self.weights)):\n",
    "            val = self.activity(numpy.dot(val, self.weights[i]))\n",
    "            val = numpy.concatenate((numpy.ones(1).T, numpy.array(val)))\n",
    "        return val[1]\n",
    "    \n",
    "    #########\n",
    "    # the predict function is used to check the prediction result of\n",
    "    # this neural network.\n",
    "    # \n",
    "    # parameters\n",
    "    # ----------\n",
    "    # self:   the class object itself\n",
    "    # X:      the input data array\n",
    "    #########\n",
    "    def predict(self, X):\n",
    "        Y = numpy.array([]).reshape(0, self.arch[-1])\n",
    "        for x in X:\n",
    "            y = numpy.array([[self.predict_single_data(x)]])\n",
    "            Y = numpy.vstack((Y,y))\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final prediction\n",
      "[0 0] 0.5725987343720323\n",
      "[0 1] 0.6634730888958555\n",
      "[1 0] 0.7074681779844519\n",
      "[1 1] 0.7651812610190181\n"
     ]
    }
   ],
   "source": [
    "numpy.random.seed(0)\n",
    "\n",
    "# Initialize the NeuralNetwork with\n",
    "# 2 input neurons\n",
    "# 2 hidden neurons\n",
    "# 1 output neuron\n",
    "nn = NeuralNetwork([2,2,1])\n",
    "\n",
    "# Set the input data\n",
    "X = numpy.array([[0, 0], [0, 1],\n",
    "                [1, 0], [1, 1]])\n",
    "\n",
    "# Set the labels, the correct results for the xor operation\n",
    "y = numpy.array([0, 1, \n",
    "                 1, 0])\n",
    "\n",
    "# Call the fit function and train the network for a chosen number of epochs\n",
    "nn.fit(X, y, epochs=10)\n",
    "\n",
    "# Show the prediction results\n",
    "print(\"Final prediction\")\n",
    "for s in X:\n",
    "    print(s, nn.predict_single_data(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def plot_decision_regions(X, y, classifier, test_idx=None, resolution=0.02):\n",
    "\n",
    "    # setup marker generator and color map\n",
    "    markers = ('s', 'x', 'o', '^', 'v')\n",
    "    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n",
    "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
    "\n",
    "    # plot the decision surface\n",
    "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n",
    "                           np.arange(x2_min, x2_max, resolution))\n",
    "    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
    "    Z = Z.reshape(xx1.shape)\n",
    "    plt.contourf(xx1, xx2, Z, alpha=0.4, cmap=cmap)\n",
    "    plt.xlim(xx1.min(), xx1.max())\n",
    "    plt.ylim(xx2.min(), xx2.max())\n",
    "\n",
    "    # plot class samples\n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(x=X[y == cl, 0], y=X[y == cl, 1],\n",
    "                    alpha=0.8, c=cmap(idx),\n",
    "                    marker=markers[idx], label=cl)\n",
    "\n",
    "    # highlight test samples\n",
    "    if test_idx:\n",
    "        # plot all samples\n",
    "        X_test, y_test = X[test_idx, :], y[test_idx]\n",
    "\n",
    "        plt.scatter(X_test[:, 0],\n",
    "                    X_test[:, 1],\n",
    "                    c='',\n",
    "                    alpha=1.0,\n",
    "                    linewidths=1,\n",
    "                    marker='o',\n",
    "                    s=55, label='test set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "numpy.random.seed(0)\n",
    "nn = NeuralNetwork([2,2,1])\n",
    "nn.fit(X, y, epochs=10)\n",
    "plot_decision_regions(X, y, nn)\n",
    "plt.xlabel('x-axis')\n",
    "plt.ylabel('y-axis')\n",
    "plt.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "buying_high      uint8\n",
       "buying_low       uint8\n",
       "buying_med       uint8\n",
       "buying_vhigh     uint8\n",
       "maint_2          uint8\n",
       "maint_3          uint8\n",
       "maint_4          uint8\n",
       "maint_5more      uint8\n",
       "doors_2          uint8\n",
       "doors_4          uint8\n",
       "doors_more       uint8\n",
       "persons_big      uint8\n",
       "persons_med      uint8\n",
       "persons_small    uint8\n",
       "lug_boot_high    uint8\n",
       "lug_boot_low     uint8\n",
       "lug_boot_med     uint8\n",
       "dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Array = [(10,10,2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurona = NeuralNetwork(Array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NeuralNetwork.__init__ of <__main__.NeuralNetwork object at 0x0000000006864EB8>>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neurona.__init__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NeuralNetwork._forward_prop of <__main__.NeuralNetwork object at 0x0000000006864EB8>>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neurona._forward_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
